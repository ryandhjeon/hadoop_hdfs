# #2 Hadoop & HDFS
__1. How much time did you spend on each part of the assignment?__

Installing Docker and setting up the hadoop environment was pretty quick, especially with the tutorial video on Apache Hadoop with Docker. 
The actual implementation part was a bit time-consuming, as understanding what is exactly going on, learning the hdfs code, and checking that every task is done right is crucial.
At the end of the day, it took about my afternoon and evening to finish and double check the tasks done.

__2. What was the hardest part of this assignment?__

Tasks on HDFS from the Command Line was the difficult part. 
I was confused where I needed to put the `RandomText.txt` and `MoreRandomText.txt` as a starter.
Looking for correct HDFS command based on the questions you asked was time-consuming, but after playing with various commands, I got used to it quickly.  

__3. What was the easiest part of this assignment?__

The easiest part was installing the Docker and setting up the Hadoop environment. Thank you for the tutorial video.

__4. What did I actually learn from doing this assignment?__

I learned the basic structure of the Hadoop system, and how I can make it interact with files in the local machine. 

__5. Why does what I learned matter both academically and practically?__

I believe the basic concept of the Hadoop system is the same. 
Even though I installed and played with it in my local machine and in Docker, the basic principle and usage should be exactly same in the practical environment, just bigger.
Being able to learn and practice with free of stress in the local environment is a great privilege.    